# Computer Science

## From 0 and 1
### Bits
The bit is a basic unit of information in computing and digital communications. A bit can have only one of two values, and may therefore be physically implemented with a two-state device. These values are most commonly represented as either a 0 or 1.
Bits (bi[nary digi]ts) are 0 and 1. 

Bits are transmitted one at a time in serial transmission, and by a multiple number of bits in parallel transmission. A bitwise operation optionally process bits one at a time. Data transfer rates are usually measured in decimal SI multiples of the unit bit per second (bit/s), such as kbit/s.

Transistors turns on and off based on how we program them.

### Bytes / Octet
The `Byte` is a unit of digital information that most commonly consists of `eight bits.
Historically, the byte was the number of bits used to encode a single character of text in a computer and for this reason it is the smallest addressable unit of memory in many computer architectures.
The de facto standard of eight bits is a convenient power of two permitting the `values 0 through 255 for one byte`.
An octet is a byte, that is eight bits. This unit of digital information is often used in computing and telecommunications when the term byte might be ambiguous, since historically there was no standard definition for the size of the byte.

A byte is symbolically marked as the upper-case B by the IEEE in contrast to the bit, lower-case b. 

### Abstracting on bytes
The patterns of 0 and 1 are interpreted depending on the extension of the file .jpg .png .mov etc.
rgb(255,34,77) uses 3 bytes.

## Algorythms
Process to do something from an input and return and output.
Computationnal thinking to formalize approaches to solve a problem.
You can `pseudocode`: "if it's rainy then I'm going to take my jacket"
* Do, open, look : they are procedures, actions, statements
* if, else, then:  they are conditionals
* you need loops to repeat commands

##Scratch
